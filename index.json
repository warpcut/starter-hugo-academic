[{"authors":null,"categories":null,"content":"I’m a Post Doc at Everyware Lab (UniMi), my reseach intrests include machine learning and its applications in medical imaging, from pathology classification, to anomaly detection and segmentation.\n","date":174096e4,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":174096e4,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a Post Doc at Everyware Lab (UniMi), my reseach intrests include machine learning and its applications in medical imaging, from pathology classification, to anomaly detection and segmentation.","tags":null,"title":"Marco Colussi","type":"authors"},{"authors":["Marco Colussi","Sergio Mascetti","Jose Dolz","Christian Desrosiers"],"categories":null,"content":"","date":174096e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":174096e4,"objectID":"2e6d661b42041bf4301d90ce8bc71172","permalink":"https://warpcut.github.io/publication/wacv25/","publishdate":"2025-03-03T00:00:00Z","relpermalink":"/publication/wacv25/","section":"publication","summary":"The remarkable progress in deep learning (DL) showcases outstanding results in various computer vision tasks. However, adaptation to real-time variations in data distributions remains an important challenge. Test-Time Training (TTT) was proposed as an effective solution to this issue, which increases the generalization ability of trained models by adding an auxiliary task at train time and then using its loss at test time to adapt the model. Inspired by the recent achievements of contrastive representation learning in unsupervised tasks, we propose ReC-TTT, a test-time training technique that can adapt a DL model to new unseen domains by generating discriminative views of the input data. ReC-TTT uses cross-reconstruction as an auxiliary task between a frozen encoder and two trainable encoders, taking advantage of a single shared decoder. This enables, at test time, to adapt the encoders to extract features that will be correctly reconstructed by the decoder that, in this phase, is frozen on the source domain. Experimental results show that ReC-TTT achieves better results than other state-of-the-art techniques in most domain shift classification challenges.","tags":["Test-time training","Contrastive feature reconstruction","Domain Adaptation"],"title":"ReC-TTT: Contrastive Feature Reconstruction for Test-Time Training","type":"publication"},{"authors":["Marco Colussi","Dragan Ahmetovic","Gabriele Civitarese","Claudio Bettini","Aiman Solyman","Roberta Gualtierotti","Flora Peyvandi","Sergio Mascetti"],"categories":null,"content":"","date":1728086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728086400,"objectID":"6be9f297d52c19b166b15f17769c11c9","permalink":"https://warpcut.github.io/publication/asmus24/","publishdate":"2024-10-05T00:00:00Z","relpermalink":"/publication/asmus24/","section":"publication","summary":"This paper presents LoRIS (Localized Reconstruction-by-Inpainting with Single-mask), a novel weakly-supervised anomaly detection technique designed to identify knee joint recess distension in musculoskeletal ultrasound images, which are noisy and unbalanced (as distended cases are rarer). In this context, supervised techniques require a high number of annotated images of both classes (distended and non-distended). On the other hand, we show that existing unsupervised anomaly detection techniques, which can be trained with images from a single class, are ineffective and often unable to correctly localize the anomaly. To overcome these issues, LoRIS is trained with nondistended images only and uses the recess bounding box as location prior to guide the reconstruction. Experimental results show that LoRIS outperforms state-of-the-art unsupervised anomaly detection techniques. When compared to a state-of-the-art fully supervised solution, LoRIS presents similar performance but has two key advantages: during training it requires images from a single class only, and it also outputs the recess segmentation, without the need for segmentation annotations.","tags":["Anomaly detection","Weak-supervision","Ultrasound images"],"title":"LoRIS - Weakly-Supervised Anomaly Detection for Ultrasound Images","type":"publication"},{"authors":["Dragan Ahmetovic","Alessio Angileri","Sara Arcudi","Claudio Bettini","Gabriele Civitarese","Marco Colussi","Andrea Giachi","Roberta Gualtierotti","Sergio Mascetti","Matteo Manzoni","Flora Peyvandi","Aiman Solyman","Addolorata Truma"],"categories":null,"content":"","date":1719792e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792e3,"objectID":"c1aa742a7f936956db1f839140841d17","permalink":"https://warpcut.github.io/publication/smartcomp24/","publishdate":"2020-11-19T00:00:00Z","relpermalink":"/publication/smartcomp24/","section":"publication","summary":"This paper describes the development of PRACTICE,a distributed healthcare technological platform that supportsvarious research initiatives by the University of Milan and theAngelo Bianchi Bonomi Hemophilia and Thrombosis Center,Fondazione IRCCS Ca’ Granda, Ospedale Maggiore Policlinico.PRACTICE includes three main components: a mobile app thatpatients can use to self-acquire ultrasound images at home,a computer-aided diagnosis web application that supports thepractitioners through a set of machine learning models, and aset of web tools for image annotation, a prerequisite for trainingthe machine learning models. Although PRACTICE was designedin the specific context of supporting the detection of joint recessblood effusions in hemophilic patients, this paper describes themain design and implementation challenges that apply to otherapplications of a research-oriented health platform.","tags":["Hemophilia","point-of-care","Deep-learning"],"title":"Insights on the Development of PRACTICE, a Research-oriented Healthcare Platform","type":"publication"},{"authors":[],"categories":null,"content":"","date":1709281800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709281800,"objectID":"87d589cafed931759caa141a0ec6077c","permalink":"https://warpcut.github.io/teaching/ambient_intelligence/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/teaching/ambient_intelligence/","section":"teaching","summary":"Università degli studi Milano-Bicocca","tags":[],"title":"Lab: Ambient Intelligence and Domotics","type":"teaching"},{"authors":["Mattia Giovanni Campana","Marco Colussi","Franca Delmastro","Sergio Mascetti","Elena Pagani"],"categories":null,"content":"","date":1704499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704499200,"objectID":"abd35c9d406ff06d967f0f300f8ede49","permalink":"https://warpcut.github.io/publication/mpox23/","publishdate":"2020-11-19T00:00:00Z","relpermalink":"/publication/mpox23/","section":"publication","summary":"In recent months, the monkeypox (mpox) virus -- previously endemic in a limited area of the world -- has started spreading in multiple countries until being declared a ``public health emergency of international concern'' by the World Health Organization. The alert was renewed in February 2023 due to a persisting sustained incidence of the virus in several countries and worries about possible new outbreaks. Low-income countries with inadequate infrastructures for vaccine and testing administration are particularly at risk. A symptom of mpox infection is the appearance of skin rashes and eruptions, which can drive people to seek medical advice. A technology that might help perform a preliminary screening based on the aspect of skin lesions is the use of Machine Learning for image classification. However, to make this technology suitable on a large scale, it should be usable directly on mobile devices of people, with a possible notification to a remote medical expert. In this work, we investigate the adoption of Deep Learning to detect mpox from skin lesion images. The proposal leverages Transfer Learning to cope with the scarce availability of mpox image datasets. As a first step, a homogenous, unpolluted, dataset is produced by manual selection and preprocessing of available image data. It will also be released publicly to researchers in the field. Then, a thorough comparison is conducted amongst several Convolutional Neural Networks, based on a 10-fold stratified cross-validation. The best models are then optimized through quantization for use on mobile devices; measures of classification quality, memory footprint, and processing times validate the feasibility of our proposal. Additionally, the use of eXplainable AI is investigated as a suitable instrument to both technically and clinically validate classification outcomes.","tags":["Machine Learning","Audio and Speech Processing","XAI"],"title":"A Transfer Learning and Explainable Solution to Detect mpox from Smartphones images","type":"publication"},{"authors":[],"categories":null,"content":"","date":1696753800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696753800,"objectID":"13c9524288e3f589a9ee77ec56d395a6","permalink":"https://warpcut.github.io/talk/gaja-proof-of-concept-msk-us-guided-self-acquisition/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/gaja-proof-of-concept-msk-us-guided-self-acquisition/","section":"event","summary":"ASMUS23 Poster Session.","tags":[],"title":"GAJA: PROOF-OF-CONCEPT MSK-US GUIDED SELF-ACQUISITION","type":"event"},{"authors":[],"categories":null,"content":"","date":1681840800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681840800,"objectID":"7d3577bfc6f58e79276518ede0774a6f","permalink":"https://warpcut.github.io/talk/multi-task-learning-for-automated-recess-detection-and-distension-classification-in-hemophilic-patients/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/multi-task-learning-for-automated-recess-detection-and-distension-classification-in-hemophilic-patients/","section":"event","summary":"Deep Learning for Medical Imaging school Poster Session.","tags":[],"title":"Multi-task learning for automated recess detection and distension classification in hemophilic patients","type":"event"},{"authors":["Marco Colussi","Sergio Mascetti","Dragan Ahmetovic","Gabriele Civitarese","Marco Cacciatori","Roberta Gualtierotti","Flora Peyvandi","Claudio Bettini"],"categories":null,"content":"","date":1675209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675209600,"objectID":"6d57d6f2ee25ad1bd9975ecd1ce59c2e","permalink":"https://warpcut.github.io/publication/asmus23/","publishdate":"2023-10-01T00:00:00Z","relpermalink":"/publication/asmus23/","section":"publication","summary":"People with hemophilia require frequent diagnoses of joint bleeding. This is currently achieved with visits to specialized centers. One possibility is to have a point-of-care acquisition of the ultrasound joint image by the patients themselves, followed by a remote evaluation by the practitioner. However, the acquisition of US images is operator-dependent, so it is unclear to what extent patients can acquire images that are suitable for remote diagnosis. In this paper, we present GAJA (Guided Acquisition of Joint ultrAsound), an application designed to guide the patient in collecting US images of their own joints, which are then transmitted to a medical practitioner. GAJA uses a collaborative interaction approach, in which an expert practitioner collects a reference US image of a specific scan during an in-person clinical visit. Anatomical markers for the target joint are automatically extracted and then used as a reference to guide the patient in properly positioning the US probe.","tags":["Machine learning","Guidance","Ultrasound images"],"title":"GAJA - Guided self-Acquisition of Joint ultrAsound images","type":"publication"},{"authors":["Marco Colussi","Gabriele Civitarese","Dragan Ahmetovic","Claudio Bettini","Roberta Gualtierotti","Flora Peyvandi","Sergio Mascetti"],"categories":null,"content":"","date":1675209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675209600,"objectID":"ae289463c934beb9b6055d364eae6809","permalink":"https://warpcut.github.io/publication/iswa23/","publishdate":"2023-02-01T00:00:00Z","relpermalink":"/publication/iswa23/","section":"publication","summary":"The paper proposes two approaches for automatically detecting joint bleeding in patients with hemophilia using ultrasound imaging. The experimental evaluation shows that the multi-task approach has higher accuracy, but with a slightly lower mean IoU value. The study suggests that computer-aided diagnosis tools can be useful for diagnosing joint bleeding in hemophilia patients.","tags":["Machine learning","Multi-task learning","Ultrasound images"],"title":"Ultrasound detection of subquadricipital recess distension","type":"publication"},{"authors":["Marco Colussi","Gabriele Civitarese","Dragan Ahmetovic","Claudio Bettini","Roberta Gualtierotti","Flora Peyvandi","Sergio Mascetti"],"categories":[],"content":"Ultrasound Detection of Subquadricipital Recess Distension Marco Colussi*, Gabriele Civitarese, Dragan Ahmetovic, Claudio Bettini, Roberta Gualtierotti, Flora Peyvandi, Sergio Mascetti\nProblem definition Context: detecting distended subquadricipital recess (SQR) needed for preventing permanent articular damage in hemofilic patients. Problem: no CAD system exists to support the practitioner Objective: create a CAD system to support the practitioner in Identifying the SQR (green box) Classifying the SQR as: Not-distended Distended SQR examples Contribution Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Detection approach In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nMulti-task approach In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nDataset Data collected from 208 hemophilic patients aged 44 ± 18.6 Images selected and annotated by expert radiologist Evaluated on 5-fold cross-validation, with patient-based splits Results Best detection Worst detection Conclusion and future works Dataset Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\n","date":1675209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675209600,"objectID":"11193a8e277b7218fe32bfcd418dcf21","permalink":"https://warpcut.github.io/slides/aixia/","publishdate":"2023-02-01T00:00:00Z","relpermalink":"/slides/aixia/","section":"slides","summary":"Ultrasound Detection of Subquadricipital Recess Distension Marco Colussi*, Gabriele Civitarese, Dragan Ahmetovic, Claudio Bettini, Roberta Gualtierotti, Flora Peyvandi, Sergio Mascetti\nProblem definition Context: detecting distended subquadricipital recess (SQR) needed for preventing permanent articular damage in hemofilic patients.","tags":[],"title":"Ultrasound Detection of Subquadricipital Recess Distension","type":"slides"},{"authors":["Roberta Gualtierotti","Sara Arcudi,","Alessandro Ciavarella","Marco Colussi","Sergio Mascetti","Claudio Bettini","Flora Peyvandi"],"categories":null,"content":"","date":1668470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668470400,"objectID":"f4669b8f9c789e24c3ecd38bb0080a88","permalink":"https://warpcut.github.io/publication/blood22/","publishdate":"2022-11-15T00:00:00Z","relpermalink":"/publication/blood22/","section":"publication","summary":"Musculoskeletal ultrasound (MSK-US) is a non-invasive and easily accessible diagnostic tool for joint health assessment of patients with hemophilia. The early identification of hemarthrosis is pivotal and could be achieved by a telemedicine system where MSK-US is performed by general practitioners or the patients themselves. The images so collected could be sent to the Comprehensive Care Center clinicians. Due to the great number of images collected, a computer-aided diagnosis (CAD) system for the automatic detection of joint effusion could support the physicians in prioritizing interventions.","tags":["Machine learning","Multi-task learning","Ultrasound images"],"title":"A Computer-Aided Diagnosis Tool for the Detection of Hemarthrosis By Remote Joint Ultrasound in Patients with Hemophilia","type":"publication"},{"authors":["Marco Colussi","Stavros Ntalampiras"],"categories":null,"content":"","date":1605744e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605744e3,"objectID":"c8d6fc3a32cd4edc491765a1ac509f9f","permalink":"https://warpcut.github.io/publication/lrp19/","publishdate":"2020-11-19T00:00:00Z","relpermalink":"/publication/lrp19/","section":"publication","summary":"arXiv","tags":["Machine Learning","Audio and Speech Processing","XAI"],"title":"Interpreting deep urban sound classification using Layer-wise Relevance Propagation","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://warpcut.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]